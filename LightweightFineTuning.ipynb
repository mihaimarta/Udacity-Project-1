{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f35354cd",
   "metadata": {},
   "source": [
    "# Lightweight Fine-Tuning Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "ec7549e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.13.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560fb3ff",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de8d76bb",
   "metadata": {},
   "source": [
    "## Loading and Evaluating a Foundation Model\n",
    "\n",
    "TODO: In the cells below, load your chosen pre-trained Hugging Face model and evaluate its performance prior to fine-tuning. This step includes loading an appropriate tokenizer and dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad741096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install -r requirements.txt\n",
    "import numpy as np\n",
    "import datetime\n",
    "import torch\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, DataCollatorWithPadding, Trainer, TrainingArguments\n",
    "from transformers.utils import logging\n",
    "from peft import LoraConfig, get_peft_model, AutoPeftModelForCausalLM, AutoPeftModelForSequenceClassification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "f551c63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train sample: {'text': 'when an alcoholic stood dribbling over a food counter', 'label': 3}\n",
      "Validation sample: {'text': 'while cycling in the country', 'label': 4}\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "dataset = load_dataset(\"dair-ai/emotion\")\n",
    "\n",
    "# Split the train set into train/validation\n",
    "train_valid = dataset[\"train\"].train_test_split(test_size=0.1, seed=42)\n",
    "\n",
    "# Inspect the dataset\n",
    "print(\"Train sample:\", train_valid[\"train\"][0])\n",
    "print(\"Validation sample:\", train_valid[\"test\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4935cb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the tokenizer\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True)\n",
    "\n",
    "tokenized_train = train_valid[\"train\"].map(tokenize, batched=True)\n",
    "tokenized_test = train_valid[\"test\"].map(tokenize, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "f28c4a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'when an alcoholic stood dribbling over a food counter', 'label': 3}\n",
      "{'text': 'while cycling in the country', 'label': 4}\n"
     ]
    }
   ],
   "source": [
    "# Label mapping\n",
    "num_labels = 4\n",
    "id2label = {0: 'joy', 1: 'anger', 2: 'fear', 3: 'sadness'}\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "\n",
    "# Check the result\n",
    "print(train_valid['train'][0])\n",
    "print(train_valid['test'][0])\n",
    "\n",
    "# Initialize the model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=num_labels,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "019b9f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistilBertForSequenceClassification(\n",
      "  (distilbert): DistilBertModel(\n",
      "    (embeddings): Embeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (transformer): Transformer(\n",
      "      (layer): ModuleList(\n",
      "        (0-5): 6 x TransformerBlock(\n",
      "          (attention): DistilBertSdpaAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (classifier): Linear(in_features=768, out_features=4, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Verify the model\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "5176b07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66,956,548 total parameters, including 593,668 trainable parameters.\n"
     ]
    }
   ],
   "source": [
    "# Freeze the model parameters\n",
    "for param in model.base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Print parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "total_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"{total_params:,} total parameters, including {total_trainable_params:,} trainable parameters.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "a8b60aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare for training\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {\"accuracy\": (predictions == labels).mean()}\n",
    "\n",
    "tokenized_train = train_valid[\"train\"].map(tokenize, batched=True)\n",
    "tokenized_test = train_valid[\"test\"].map(tokenize, batched=True)\n",
    "data_collator = DataCollatorWithPadding(tokenizer, padding=True)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"./results/{model_name}/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"),\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    warmup_steps=300,\n",
    "    learning_rate=3e-5,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy=\"epoch\",\n",
    "    eval_strategy=\"epoch\", \n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "83604aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mihai.marta/Development/Udacity/fine-tuning/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.164207935333252, 'eval_model_preparation_time': 0.0008, 'eval_accuracy': 0.09875, 'eval_runtime': 2.4701, 'eval_samples_per_second': 647.746, 'eval_steps_per_second': 20.242}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.164207935333252,\n",
       " 'eval_model_preparation_time': 0.0008,\n",
       " 'eval_accuracy': 0.09875,\n",
       " 'eval_runtime': 2.4701,\n",
       " 'eval_samples_per_second': 647.746,\n",
       " 'eval_steps_per_second': 20.242}"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the base model\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d52a229",
   "metadata": {},
   "source": [
    "## Performing Parameter-Efficient Fine-Tuning\n",
    "\n",
    "TODO: In the cells below, create a PEFT model from your loaded model, run a training loop, and save the PEFT model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "5775fadf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,036,036 || all params: 67,992,584 || trainable%: 1.5237\n"
     ]
    }
   ],
   "source": [
    "# Use label_list, label2id, id2label from earlier preprocessing\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Use label_list, label2id, id2label from your preprocessing cell\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=num_labels,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    ignore_mismatched_sizes=True\n",
    ")\n",
    "\n",
    "# Define the LoRA configuration\n",
    "config = LoraConfig(\n",
    "    task_type='SEQ_CLS',\n",
    "    target_modules=[\"q_lin\", \"k_lin\", \"v_lin\"],\n",
    "    r=16,\n",
    "    lora_alpha=64,\n",
    "    lora_dropout=0.05\n",
    ")\n",
    "\n",
    "# Apply LoRA to the model\n",
    "fine_tuned_model = get_peft_model(model, config)\n",
    "\n",
    "# Print trainable parameters\n",
    "fine_tuned_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "894046c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2w/_r_x96_s2_v2zk9tn6bhxkj80000gp/T/ipykernel_18114/3711282236.py:21: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  lora_trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "# Prepare for training\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {\"accuracy\": (predictions == labels).mean()}\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"./results/{model_name}-lora/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"),\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    warmup_steps=300,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "lora_trainer = Trainer(\n",
    "    model=fine_tuned_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "c4d4c908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5760677456855774, 'eval_accuracy': 0.6225, 'eval_runtime': 2.7034, 'eval_samples_per_second': 591.857, 'eval_steps_per_second': 18.496, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mihai.marta/Development/Udacity/fine-tuning/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8975, 'grad_norm': 2.527202844619751, 'learning_rate': 1.7958974358974363e-05, 'epoch': 1.1111111111111112}\n",
      "{'eval_loss': 0.4066803455352783, 'eval_accuracy': 0.673125, 'eval_runtime': 2.7073, 'eval_samples_per_second': 590.995, 'eval_steps_per_second': 18.469, 'epoch': 2.0}\n",
      "{'eval_loss': 0.4066803455352783, 'eval_accuracy': 0.673125, 'eval_runtime': 2.7073, 'eval_samples_per_second': 590.995, 'eval_steps_per_second': 18.469, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mihai.marta/Development/Udacity/fine-tuning/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4865, 'grad_norm': 1.2797263860702515, 'learning_rate': 1.2830769230769232e-05, 'epoch': 2.2222222222222223}\n",
      "{'eval_loss': 0.3449048101902008, 'eval_accuracy': 0.694375, 'eval_runtime': 2.7328, 'eval_samples_per_second': 585.477, 'eval_steps_per_second': 18.296, 'epoch': 3.0}\n",
      "{'eval_loss': 0.3449048101902008, 'eval_accuracy': 0.694375, 'eval_runtime': 2.7328, 'eval_samples_per_second': 585.477, 'eval_steps_per_second': 18.296, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mihai.marta/Development/Udacity/fine-tuning/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3888, 'grad_norm': 5.792016983032227, 'learning_rate': 7.702564102564102e-06, 'epoch': 3.3333333333333335}\n",
      "{'eval_loss': 0.3149174749851227, 'eval_accuracy': 0.70625, 'eval_runtime': 2.7316, 'eval_samples_per_second': 585.729, 'eval_steps_per_second': 18.304, 'epoch': 4.0}\n",
      "{'eval_loss': 0.3149174749851227, 'eval_accuracy': 0.70625, 'eval_runtime': 2.7316, 'eval_samples_per_second': 585.729, 'eval_steps_per_second': 18.304, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mihai.marta/Development/Udacity/fine-tuning/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3454, 'grad_norm': 4.225612640380859, 'learning_rate': 2.5743589743589746e-06, 'epoch': 4.444444444444445}\n",
      "{'eval_loss': 0.30747634172439575, 'eval_accuracy': 0.710625, 'eval_runtime': 2.7063, 'eval_samples_per_second': 591.224, 'eval_steps_per_second': 18.476, 'epoch': 5.0}\n",
      "{'eval_loss': 0.30747634172439575, 'eval_accuracy': 0.710625, 'eval_runtime': 2.7063, 'eval_samples_per_second': 591.224, 'eval_steps_per_second': 18.476, 'epoch': 5.0}\n",
      "{'train_runtime': 305.5558, 'train_samples_per_second': 235.636, 'train_steps_per_second': 7.364, 'train_loss': 0.5086749877929687, 'epoch': 5.0}\n",
      "{'train_runtime': 305.5558, 'train_samples_per_second': 235.636, 'train_steps_per_second': 7.364, 'train_loss': 0.5086749877929687, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2250, training_loss=0.5086749877929687, metrics={'train_runtime': 305.5558, 'train_samples_per_second': 235.636, 'train_steps_per_second': 7.364, 'train_loss': 0.5086749877929687, 'epoch': 5.0})"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the LoRA model \n",
    "lora_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "b47abf88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mihai.marta/Development/Udacity/fine-tuning/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.30747634172439575, 'eval_accuracy': 0.710625, 'eval_runtime': 2.7041, 'eval_samples_per_second': 591.69, 'eval_steps_per_second': 18.49, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.30747634172439575,\n",
       " 'eval_accuracy': 0.710625,\n",
       " 'eval_runtime': 2.7041,\n",
       " 'eval_samples_per_second': 591.69,\n",
       " 'eval_steps_per_second': 18.49,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the LoRA model\n",
    "lora_trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "3bb6b396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the loRA model\n",
    "fine_tuned_model.save_pretrained(f\"./peft/{model_name}-lora\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615b12c6",
   "metadata": {},
   "source": [
    "## Performing Inference with a PEFT Model\n",
    "\n",
    "TODO: In the cells below, load the saved PEFT model weights and evaluate the performance of the trained PEFT model. Be sure to compare the results to the results from prior to fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc96905a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2w/_r_x96_s2_v2zk9tn6bhxkj80000gp/T/ipykernel_18114/3731146215.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  lora_eval_trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.307373046875, 'eval_model_preparation_time': 0.001, 'eval_accuracy': 0.71, 'eval_runtime': 4.5139, 'eval_samples_per_second': 354.464, 'eval_steps_per_second': 44.308}\n"
     ]
    }
   ],
   "source": [
    "# Load the saved PEFT model and evaluate performance\n",
    "loaded_lora_model = AutoPeftModelForSequenceClassification.from_pretrained(\n",
    "    f\"./peft/{model_name}-lora\",\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    ignore_mismatched_sizes=True,\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "\n",
    "# Move model to device\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "loaded_lora_model = loaded_lora_model.to(device)\n",
    "\n",
    "# Evaluate on the test set\n",
    "lora_eval_trainer = Trainer(\n",
    "    model=loaded_lora_model,\n",
    "    eval_dataset=tokenized_test,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "lora_eval_results = lora_eval_trainer.evaluate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "7cb9983b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.164207935333252, 'eval_model_preparation_time': 0.0008, 'eval_accuracy': 0.09875, 'eval_runtime': 2.594, 'eval_samples_per_second': 616.813, 'eval_steps_per_second': 19.275}\n",
      "Accuracy Comparison:\n",
      "PEFT Model Accuracy: 0.71\n",
      "Base Model Accuracy: 0.09875\n"
     ]
    }
   ],
   "source": [
    "# Print only the accuracy comparison between PEFT and base models\n",
    "peft_accuracy = lora_eval_results.get('eval_accuracy', None)\n",
    "try:\n",
    "    base_results = trainer.evaluate()\n",
    "    base_accuracy = base_results.get('eval_accuracy', None)\n",
    "except Exception as e:\n",
    "    base_accuracy = None\n",
    "\n",
    "print(\"Accuracy Comparison:\")\n",
    "print(f\"PEFT Model Accuracy: {peft_accuracy}\")\n",
    "print(f\"Base Model Accuracy: {base_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb050e5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
